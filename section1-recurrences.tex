\chapter{Deterministic Recurrences as Infinite Sums}
In section 1, Karp states that the expected cost of stochastic processes that appear in divide-and-conquer algorithms may be 
described by
recurrence relations of the form $T(x) = a(x) + T(h(x))$, where $x$ is a non-negative real number, $h(x)$ and $T(x)$ are 
random variables, and $a$ is a non-negative, real-valued function. He then offers a deterministic counterpart to this
probabilistic recurrence, $T'(x) = a(x) + T'(m(x))$, where $m$ is a real-valued function such that for 
$\forall x \in \R, \ E(h(x)) \leq m(x) , 0 \leq m(x)$, and $m(x), m(x)/x$ are nondecreasing. He asserts that this recurrence 
has a least nonnegative solution $u$ given by the Tarski fixed-point theorem, $u(x) = \sum_{i=1}^{\infty}a(m^i(x))$, where 
$m^i$ is the $i^{th}$ iterate of $m$. The solution $u$ and the function $m$ are used in theorems 1.1 and 1.2 to obtain a 
bound on the upper tail of $T(x)$.

In this chapter, we will define an expression language that allows us to write and type-check
deterministic recurrences such as $T'$. Further, we will define a denotational semantics for this language, 
such that the interpretation of our recurrences exhibit the same behavior as Karp's recurrences. 

Consider that, in order to describe recurrence relations, our language must have some way of defining recursive functions.
A first attempt at this involves defining a PCF-like language with a $\texttt{real}$ type and a $\texttt{fix}$ operator
that assigns the least fixed-point to continuous functions using the CPO fixed-point theorem. Our denotational semantics 
then interprets all base types as flat-ordered CPOs---for instance, $\texttt{real}$  interprets to $R_{\perp}$, the reals with a 
bottom element $\perp$, with each real number comparable only to $\perp$. Following standard PCF, arrow types
$\tau \rightarrow \sigma$, interpret to a CPO whose bottom element is a function $\perp: \tau \rightarrow \sigma$ such
that $\perp(x) = \perp_{\sigma}, \forall x \in \tau$.

However, this approach proves problematic, due to the fact that the standard interpretation of the base operations is strict---e.g. the 
sum of $\perp$ and any other element should be $\perp$. However, if we consider a function $F: (\R_{\perp} \rightarrow 
\R_{\perp}) \rightarrow (\R_{\perp} \rightarrow \R_{\perp})$ such that $F(g) = a(x) + g(px)$, then by the CPO fixed-point
theorem, the least fixed point of F is $\bigvee\{F^n(\perp)\}^{\infty}_{n=1}$. Then 
\begin{align*}
F(\perp)(x) &= a(x) + \perp(px)\\
&= a(x) + \perp \\
&= \perp 
\end{align*}
so by induction we may show that for $\forall n, \ F^n(\perp)(x) = \perp \implies \bigvee\{F^n(\perp)\}^{\infty}_{n=1}  = \perp$. 
This result, is, clearly, not a solution to the recurrence $T(x) + a(x) + T(px)$, making this denotational semantics
unusable to us. 

A second approach involves altering the interpretation of the $\texttt{real}$ type to 
$\extR$---that is, the non-negative, extended reals. See that $\extR$ is a CPO: $0$ is a bottom element,
and any directed subset of $\extR$ must have a least upper bound. Such an interpretation
resolves the issue of all recursive functions interpreting to $\perp$. In the above example, for instance, we would have
\begin{align*}
F(\perp)(x) &= a(x) + \perp(px)\\
&= a(x) + 0 \\
&= a(x) \\
F(F(\perp))(x) &= a(x) + F(\perp)(px) \\
&= a(x) + a(px)
\end{align*}
so, by induction, 
$\forall n, \ F^n(\perp)(x) = \sum_{i=1}^{n}a(p^{i-1}x) \ \implies \bigvee\{F^n(\perp)\}^{\infty}_{n=1}(x) = \sum_{i=1}^{\infty}
a(p^{i-1}x)$. This $\emph{is}$ the solution to the recurrence $T(x) = a(x) + T(px)$, suggesting that this is the 
appropriate denotational semantics to use. However, this causes unexpected problems. For one, note that
 the standard interpretation of the equality operator is as follows:
\begin{align*}
 \llbracket e_1 = e_2 \rrbracket\eta &= 
 \begin{cases} 
      true \text{ if } (\llbracket e_1 \rrbracket\eta = \llbracket e_2 \rrbracket\eta \neq \perp) \\
      false \text{  if } (\llbracket e_1 \rrbracket\eta \neq \llbracket e_2\rrbracket\eta, \llbracket e_1 \rrbracket\eta \neq \perp, \llbracket e_2 \rrbracket\eta \neq \perp)\\
      \perp \text{ otherwise}
   \end{cases} 
\end{align*}
with similar rules for $<, >, \leq, \geq$. But if our bottom element of $\llbracket \texttt{real} \rrbracket$ is $0$, this 
prohibits us from writing a program where we compare a number to $0$. This is too restrictive, as there are many 
divide-and-conquer algorithms where we continue a process on the condition that an integer is non-negative, or a 
list is non-empty. Then we must rewrite our interpretation of such expressions as
\begin{align*}
 \llbracket e_1 = e_2 \rrbracket\eta &= 
 \begin{cases} 
      true \text{ if } \llbracket e_1 \rrbracket\eta = \llbracket e_2 \rrbracket\eta \\
      false \text{  if } \llbracket e_1 \rrbracket\eta \neq \llbracket e_2\rrbracket\eta\\
   \end{cases} 
\end{align*}

To see why this is a problem, consider the expression $x = \texttt{0}$ and the chain $\{n\}_{n=0}^{\infty} \in \llbracket 
\texttt{real} \rrbracket$. See, then, that
\begin{align*}
\llbracket x = \texttt{0} \rrbracket\{x \mapsto 0\} &= true \\
\llbracket x = \texttt{0} \rrbracket\{x \mapsto 1\} &= false \\
\llbracket x = \texttt{0} \rrbracket\{x \mapsto 2\} &= false \\
\ldots
\end{align*}
so, since $\llbracket \texttt{bool} \rrbracket$ is flat-ordered, the set 
$\{\llbracket x = \texttt{0}\rrbracket\{x \mapsto n\}\}_{n=0}^{\infty}$ has no supremum. However, as we will see in chapter 3,
in order to use the CPO fixed-point theorem it will be necessary to show that for all expressions $e$, environments $\Gamma$,
and chains $a_0 \leq a_1 \leq \ldots,$
\begin{align*}
  \llbracket \Gamma \vdash e : \tau \rrbracket\eta\{x\mapsto \bigvee_i a_i\}
  = \bigvee_i \llbracket \Gamma \vdash e : \tau \rrbracket\eta\{x \mapsto a_i\}
\end{align*}
%Also, (interpretation of non-terminating functions).

Thus, this approach will not work. In light of this, we define the following expression language. 
\[
\begin{array}{rcl}
\tau &::=& \texttt{real} \mid \texttt{bool} \mid \tau \times \tau \mid \tau \rightarrow \tau \\
e &::=& x  \mid \texttt{0} \mid \texttt{1} \mid \texttt{2} \mid \dotsc \mid \lambda x.e \mid e \ e \mid e + e \mid e - e \mid  e  *  e \mid e / e \mid \texttt{true} \mid \texttt{false} \mid \\
  && e  =  e \mid e < e \mid e > e \ | e \leq e \mid e \geq e \mid 
     \ifelse{e}{e}{e} \mid \\
    && \texttt{rec}(\lambda x.e, \lambda x.e) 
\end{array}
\]

Note that there is no $\texttt{fix}$ operator---instead, we have a $\texttt{rec}$ operator, which allows us to write 
recurrences of the form $T(x) = a(x) + T(m(x))$, where $T$, $a$, and $m$ are real-valued functions. While this is a very 
restrictive subset of recursive functions, it allows us to express the recurrences described by Karp in section 1, without
running into the problems of the previous approaches. 

\begin{figure}
\[
\begin{array}{lr}
\dfrac{}{\Gamma \vdash \texttt{0}: \texttt{real}}, \ \ \dfrac{}{\Gamma \vdash \texttt{1}: \texttt{real}}, \ldots \\ \\
\dfrac{}{\Gamma \vdash \texttt{true} : \texttt{bool}}, \ \ \dfrac{}{\Gamma \vdash \texttt{false} : \texttt{bool}} \\  \\
\dfrac{x : \tau \in \Gamma}{\Gamma \vdash x : \tau } \\ \\ 
\dfrac{\Gamma, x : \sigma \vdash e : \tau}{\Gamma \vdash \lambda (x : \sigma).e : \sigma \rightarrow \tau } \\ \\
\dfrac{\Gamma \vdash e_1: \sigma \rightarrow \tau \ \ \ \Gamma \vdash e_2 : \sigma}{\Gamma \vdash e_1 \ e_2 : \tau} \\ \\
\dfrac{\Gamma \vdash e_1 : \texttt{real} \ \ \ \Gamma \vdash e_2 : \texttt{real}}{\Gamma \vdash e_1 \circ e_2 : \texttt{real}}
, \circ \in \{+,-,*,/\} \\ \\ 
\dfrac{\Gamma \vdash e_1 : \texttt{real} \ \ \ \Gamma \vdash e_2 : \texttt{real}}{\Gamma \vdash e_1 \circ e_2 : \texttt{bool}}
, \circ \in \{=, <, >, \geq, \leq\} \\ \\ 
\dfrac{\Gamma \vdash e_1 : \texttt{bool} \ \ \ \Gamma \vdash e_2 : \tau \ \ \ \Gamma \vdash e_3 : \tau}
{\Gamma \vdash \ifelse{e_1}{e_2}{e_3} : \tau} \\ \\ 
\dfrac{\Gamma \vdash \lambda x.e_1 : \texttt{real} \rightarrow \texttt{real} \ \ \ \Gamma \vdash \lambda x.e_2 : 
\texttt{real} \rightarrow \texttt{real}}
{\Gamma \vdash \texttt{rec}(\lambda x.e_1, \lambda x.e_2) : \texttt{real} \rightarrow \texttt{real}} 
\end{array}
\]
\caption{Typing for the language.}
\label{fig:typing}
\end{figure}

\begin{figure}
\[
\begin{array}{lr}
e = e \\ \\
\texttt{0} + \texttt{0} = \texttt{0}, \ \texttt{0} + \texttt{1} = 1, \ldots, \ \texttt{3} + \texttt{5} = \texttt{8}, \ldots  \\
\text{equivalent rules for } -, \ * \text{, and } /\text{ operations.}
\\ \\
(n =n) = \texttt{true} \\ (n=m) = \texttt{false}\text{, provided } n, \ m \text{ distinct numerals.}\\ \\ 
\ifelse{\texttt{ true }}{e_1}{e_2} = e_1 \\
\ifelse{\texttt{ false }}{e_1}{e_2} = e_2 \\ \\ 
\lambda x.e = \lambda y.[x \mapsto y]e, \text{provided } y \text{ not free in } e. \\ \\ 
\lambda x.e_1 \ e_2 = [x \mapsto e_2]e_1 \\
\texttt{rec}(\lambda x.e_1, \lambda x.e_2) = 
			\lambda x.(e_1 + \texttt{rec}(\lambda x.e_1, \lambda x.e_2)(e_2)) 
\end{array}
\]
\caption{Equational semantics for the language.}
\label{fig:eqsem}
\end{figure}

\begin{figure}
 \begin{align*}
\llbracket \texttt{real} \rrbracket &= \R \\
 \llbracket \texttt{bool} \rrbracket &= {\{true, false\}} \\
 \llbracket \tau \times \sigma \rrbracket &= \llbracket \tau \rrbracket \times \llbracket \sigma \rrbracket  \\
 \llbracket \tau \rightarrow \sigma \rrbracket &= \{f: \llbracket \tau \rrbracket \rightarrow \llbracket \sigma \rrbracket \mid
 \ f \text{ is continuous}\} 
 \end{align*}
 \caption{Denotational semantics for types.}
 \label{fig:densemtypes}
 \end{figure}
 \begin{figure}
\begin{align*}
 \llbracket \texttt{0} \rrbracket\eta &= 0, \  \llbracket \texttt{1} \rrbracket\eta = 1, \ \ldots \\
  \llbracket x : \tau \rrbracket\eta &= \eta(x) \\
  \llbracket \lambda (x : \tau) . (e : \sigma) \rrbracket\eta &= f : \llbracket \tau \rrbracket \rightarrow \llbracket \sigma \rrbracket \\
\text{ s.t. } \forall d \in \llbracket \tau \rrbracket, f(d) &= \llbracket e \rrbracket\eta\{ x \mapsto d \} \\
 \llbracket e_1 \ e_2 \rrbracket \eta &= \llbracket e_1 \rrbracket\eta ( \llbracket e_2 \rrbracket\eta ) \\
 \llbracket e_1 + e_2 \rrbracket\eta &= \llbracket e_1 \rrbracket\eta + \llbracket e_2 \rrbracket\eta \\
 \llbracket e_1 - e_2 \rrbracket\eta &= \llbracket e_1 \rrbracket\eta - \llbracket e_2 \rrbracket\eta \\
 \llbracket e_1 * e_2 \rrbracket\eta &= \llbracket e_1 \rrbracket\eta * \llbracket e_2 \rrbracket\eta \\
  \llbracket e_1 / e_2 \rrbracket\eta &= \llbracket e_1 \rrbracket\eta / \llbracket e_2 \rrbracket\eta \\
  \llbracket \texttt{true} \rrbracket\eta &= true, \ \llbracket \texttt{false} \rrbracket\eta = false \\
 \llbracket e_1 = e_2 \rrbracket\eta &= 
 \begin{cases} 
      true \text{ if } \llbracket e_1 \rrbracket\eta = \llbracket e_2 \rrbracket\eta \\
      false \text{  if } \llbracket e_1 \rrbracket\eta \neq \llbracket e_2\rrbracket\eta \\
   \end{cases}
 \\
\text{Similar rules for $<, \ \leq , >$\, and $\geq$} \\
  \llbracket \ifelse{e_1}{e_2}{e_3} \rrbracket \eta &= 
 \begin{cases} 
      \llbracket e_2 \rrbracket\eta \text{ if } \llbracket e_1 \rrbracket\eta = true \\
      \llbracket e_3 \rrbracket\eta \text{ if } \llbracket e_1 \rrbracket\eta = false \\
   \end{cases}
  \\
   \llbracket  \texttt{rec} (e_1 : \texttt{real} \rightarrow \texttt{real}, e_2 : \texttt{real} \rightarrow \texttt{real}) \rrbracket\eta &= rec : \R \rightarrow \R \text{ s.t. } \forall d \in \R, \\
   rec(d) &= \sum_{i=0}^{\infty}\llbracket \lambda x.e_1 \rrbracket\eta ((\llbracket \lambda x.e_2 \rrbracket\eta)^i(d))
 \end{align*}
 \caption{Denotational semantics for expressions.}
 \label{fig:densemexps}
 \end{figure}
 
  We will prove soundness of our denotation for $\texttt{rec}$ expressions, in order to ensure that
 our interpretation of recurrences reflects their equational meaning.
 \begin{thm}
 \begin{align*}
 \llbracket \texttt{rec}(\lambda x.e_1, \lambda x.e_2) \rrbracket \eta 
 = \llbracket \lambda x.(e_1 + \texttt{rec}(\lambda x.e_1, \lambda x.e_2)(e2)) \rrbracket \eta
 \end{align*} 
 \end{thm}
 
 \begin{proof}
 Note that
 \begin{align*}
 \llbracket \lambda x.(e_1 + \texttt{rec}(\lambda x.e_1, \lambda x.e_2)(e_2)) \rrbracket \eta
 &= f : \R \rightarrow \R \text{ s.t. } \forall d \in \R, \\
 f(d) =  \llbracket e_1 \rrbracket\{x\mapsto d\} &+ \llbracket \texttt{rec}(\lambda x.e_1, \lambda x.e_2)(e_2)\rrbracket\eta
 \{x\mapsto d\} \\
 = \llbracket \lambda x.e_1\rrbracket(d) &+ \llbracket\texttt{rec}(\lambda x.e_1, \lambda x.e_2)\rrbracket\eta
 (\llbracket e_2 \rrbracket\eta\{x \mapsto d\}) \\
 =  \llbracket \lambda x.e_1\rrbracket(d) &+ \llbracket\texttt{rec}(\lambda x.e_1, \lambda x.e_2)\rrbracket\eta
 (\llbracket \lambda x.e_2 \rrbracket(d)) \\
 = \llbracket \lambda x.e_1\rrbracket(d) &+ \sum_{i=0}^{\infty} \llbracket \lambda x.e_1\rrbracket\eta
 ((\llbracket \lambda x.e_2 \rrbracket\eta)^i (\llbracket \lambda x.e_2\rrbracket\eta(d))) \\
 = \llbracket \lambda x.e_1\rrbracket(d) &+ \sum_{i=1}^{\infty} \llbracket \lambda x.e_1\rrbracket\eta
 ((\llbracket \lambda x.e_2 \rrbracket\eta)^i (d)) \\
&= \sum_{i=0}^\infty \llbracket \lambda x.e_1 \rrbracket\eta ((\llbracket \lambda x.e_2\rrbracket\eta)^i(d)) \\
&=  \llbracket \texttt{rec}(\lambda x.e_1, \lambda x.e_2) \rrbracket \eta (d)
\end{align*}
\end{proof}

\section{Example}
Consider the example Karp offers, wherein $m(x) = px$, with $p$ a
positive constant less than 1, and $a(x) = 0, \ x < 1, \ a(x) = 1, \ x \geq 1$.
Then $T(x) = a(x) + T(px)$, so by a simple inductive argument we can show that 

\begin{align*}
T(x) &= 
 \begin{cases}
 0 \text{ if } x < 1 \\
 k \text{ if }  \dfrac{1}{p^{k-1}} \leq x < \dfrac{1}{p^k} \\
 \end{cases}
 \end{align*}
 We express this function in our expression language as follows: 
 \begin{align*}
 \texttt{T} = \texttt{rec}(\lambda x.(\ifelse{x<\texttt{1}}{\texttt{0}}{\texttt{1}}), \lambda x. \texttt{p}*x)
 \end{align*}
 We want to show that the interpretation of this expression has the same behavior as the function described by Karp.
 Let $\texttt{a} = \lambda x.\ifelse{x<1}{0}{1}, \ \texttt{m} = \lambda x.\texttt{p}*x$, and see that
 \begin{align*}
  \llbracket \texttt{a} \rrbracket &= \underline{a} : \R \rightarrow \R \text{ s.t. } \underline{a}(d) = 0, 
  \ d<1, \underline{a}(d) = 1, \ d \geq 1  \\
 \llbracket \texttt{m} \rrbracket &= \underline{m} : \R \rightarrow \R \text{ s.t } \forall d \in \R, \
 \underline{m}(d) = pd \\
 \llbracket \texttt{T} \rrbracket&= \llbracket \texttt{rec}(\texttt{a}, \texttt{m}) \rrbracket \\
 &= rec: \R \rightarrow \R \text{ s.t. } \forall d \in \R, \\
 &rec(d) = \sum_{i=0}^{\infty}\llbracket \texttt{a} \rrbracket (\llbracket \texttt{m} \rrbracket^i(d)) \\
 &= \sum_{i=0}^{\infty}\underline{a} (\underline{m}^i(d)) \\
 &= \sum_{i=0}^{\infty}\underline{a} (p^i(d))
 \end{align*}
Note that, for $\forall d<1 \in \R, \ \llbracket \texttt{T} \rrbracket(d) = 0$
and for $\forall d \geq 1 \in R$, since $p < 1, \ \exists k \in \N \text{ s.t } \dfrac{1}{p^{k-1}} \leq d < \dfrac{1}{p^k}$. Then
\begin{align*}
\llbracket \texttt{T} \rrbracket(d)&= \sum_{i=0}^{\infty}\underline{a} (p^i(d)) \\
&= \sum_{i=0}^{k-1}\underline{a} (p^i(d)) + \sum_{i=k}^{\infty}\underline{a} (p^i(d)) \\
&= k + 0 \\
&= k
\end{align*}
Therefore, $\llbracket \texttt{T} \rrbracket = T$
 

