\chapter{Deterministic Recurrences as Infinite Sums}
\cite[\S1]{Karp} states that the  cost of recursive, stochastic algorithms may 
be described by recurrence relations of the form $T(x) = a(x) + T(h(x))$, where $x$ is a non-negative real number, $h(x)$ 
and $T(x)$ are 
random variables, and $a$ is a non-negative, real-valued function. He then offers a deterministic counterpart to this
probabilistic recurrence, $T'(x) = a(x) + T'(m(x))$, where $m$ is a real-valued function such that for all
$ x \in \R, \ E(h(x)) \leq m(x) , 0 \leq m(x)$, and $m(x), m(x)/x$ are nondecreasing. He asserts that when $T'$ has a
non-negative solution, it has a least solution $u$ given by $u(x) = \sum_{i=1}^{\infty}a(m^i(x))$, where 
$m^i$ is the $i^{th}$ iterate of $m$. 

In this chapter, we will define an expression language that allows us to write and type-check
deterministic recurrences such as $T'$. Further, we will define a denotational semantics for this language, 
such that the interpretations of a recurrence is equal to its solution. 

Consider that, in order to describe recurrence relations, our language must have some way of defining recursive functions.
A first attempt at this involves defining a PCF-like language with a $\texttt{real}$ type and a $\texttt{fix}$ operator
that assigns the least fixed-point to continuous functions using the CPO fixed-point theorem
(the details of such a language are described further in chapter 3). Our denotational semantics 
then interprets all base types as flat-ordered CPOs---for instance, $\texttt{real}$  interprets to $R_{\perp}$, the reals with a 
bottom element $\perp$, with each real number comparable only to $\perp$. Following standard PCF, arrow types
$\tau \rightarrow \sigma$ interpret to a CPO whose bottom element is a function $\perp: \tau \rightarrow \sigma$ such
that $\perp(x) = \perp_{\sigma}, \forall x \in \tau$. A recursively-defined function $f$ is interpreted as 
$\bigvee_n\{F^n \perp\}$, where $F: (\real \rightarrow \real) \rightarrow (\real \rightarrow \real)$ is derived from
the recursive definition.

However, this approach proves problematic, due to the fact that the only obvious interpretation of the base operations is strict---that is, it does not make sense for the 
sum of $\perp$ and another element to be anything other than $\perp$. The function $F$ used to interpret a recurrence
such as $T(x) = a(x) + T(m(x))$ has the form $F(g)(x) = a(x) + g(m(x))$. But if addition is strict, then 
\begin{align*}
F(\perp)(x) &= a(x) + \perp(px) = a(x) + \perp = \perp 
\end{align*}
so by induction we may show that for all $n, \ F^n(\perp)(x) = \perp$, so $\bigvee\{F^n(\perp)\}^{\infty}_{n=1}  = \perp$. 
This result, is, clearly, not a solution to the recurrence $T(x) = a(x) + T(px)$, making this denotational semantics
unsuitable. 

A second approach involves altering the interpretation of the $\texttt{real}$ type to 
$\extR$---the non-negative, extended reals. See that $\extR$ is a CPO: $0$ is a bottom element,
and any directed subset of $\extR$ must have a least upper bound. Such an interpretation
resolves the issue of all recursive functions interpreting to $\perp$, because there is now a reasonable, non-strict
interpretation of the base functions---e.g., $x + 0 = x$. In the above example, for instance, we would have
\begin{align*}
F(\perp)(x) &= a(x) + \perp(px) = a(x) + 0 = a(x) \\
F(F(\perp))(x) &= a(x) + F(\perp)(px) = a(x) + a(px)
\end{align*}
so, by induction, 
$\forall n, \ F^n(\perp)(x) = \sum_{i=1}^{n}a(p^{i-1}x)$, and hence $\bigvee\{F^n(\perp)\}^{\infty}_{n=1}(x) = \sum_{i=1}
^{\infty}a(p^{i-1}x)$. This $\emph{is}$ the solution to the recurrence $T(x) = a(x) + T(px)$, suggesting that this is the 
appropriate denotational semantics to use. However, this causes unexpected problems. Note that
 the standard interpretation of the equality operator is as follows:
\begin{align*}
 \llbracket e_1 = e_2 \rrbracket\eta &= 
 \begin{cases} 
      true \text{ if } (\llbracket e_1 \rrbracket\eta = \llbracket e_2 \rrbracket\eta \neq \perp) \\
      false \text{  if } (\llbracket e_1 \rrbracket\eta \neq \llbracket e_2\rrbracket\eta, \llbracket e_1 \rrbracket\eta \neq \perp, \llbracket e_2 \rrbracket\eta \neq \perp)\\
      \perp \text{ otherwise}
   \end{cases} 
\end{align*}
with similar rules for $<, >, \leq, \geq$. But if our bottom element of $\llbracket \texttt{real} \rrbracket$ is $0$, this 
prohibits us from writing a program where we compare a number to $0$. This is too restrictive, as there are many 
divide-and-conquer algorithms where we continue a process on the condition that, say, an integer is non-negative, or a 
list is non-empty. Then we have to rewrite our interpretation of such expressions as
\begin{align*}
 \llbracket e_1 = e_2 \rrbracket\eta &= 
 \begin{cases} 
      true \text{ if } \llbracket e_1 \rrbracket\eta = \llbracket e_2 \rrbracket\eta \\
      false \text{  if } \llbracket e_1 \rrbracket\eta \neq \llbracket e_2\rrbracket\eta\\
   \end{cases} 
\end{align*}

To see why this is a problem, consider the expression $x = 0$ and the chain $\{n\}_{n=0}^{\infty} \in \llbracket 
\texttt{real} \rrbracket$. See, then, that
\begin{align*}
\llbracket x = \texttt{0} \rrbracket\{x \mapsto 0\} &= true \\
\llbracket x = \texttt{0} \rrbracket\{x \mapsto 1\} &= false \\
\llbracket x = \texttt{0} \rrbracket\{x \mapsto 2\} &= false \\
\ldots
\end{align*}
so, since the standard interpretation of $\llbracket \texttt{bool} \rrbracket$ is flat-ordered---and there is no obvious
alternative interpretation---$\{\llbracket x = 0\rrbracket\{x \mapsto n\}\}_{n=0}^{\infty}$ has no supremum. However, as we will see in chapter 3,
in order to use the CPO fixed-point theorem it will be necessary to show that for all expressions $e$
and chains $a_0 \leq a_1 \leq \ldots,$
\begin{align*}
  \llbracket \Gamma \vdash e : \tau \rrbracket\eta\{x\mapsto \bigvee_i a_i\}
  = \bigvee_i \llbracket \Gamma \vdash e : \tau \rrbracket\eta\{x \mapsto a_i\}
\end{align*}

Thus, this approach will not work either. In light of this, we define the a language that replaces the general fixed-point 
operator with a special-purpose recursive operator. Typing and equational semantics are given in Figures 1 and 2.
\[
\begin{array}{rcl}
\tau &::=& \texttt{real} \mid \texttt{bool} \mid \tau \times \tau \mid \tau \rightarrow \tau \\
e &::=& x  \mid \texttt{0} \mid \texttt{1} \mid \texttt{2} \mid \dotsc \mid \lambda x.e \mid e \ e \mid e + e \mid e - e \mid  e  *  e \mid e / e \mid \texttt{true} \mid \texttt{false} \mid \\
  && e  =  e \mid e < e \mid e > e \ | e \leq e \mid e \geq e \mid 
     \ifelse{e}{e}{e} \mid (e,e) \mid \\
    && \texttt{floor}(e) \mid \texttt{rec}(\lambda x.e, \lambda x.e) 
\end{array}
\]

The $\texttt{rec}$ operator allows us to write 
recurrences of the form $T(x) = a(x) + T(m(x))$, where $T$, $a$, and $m$ are real-valued functions.
The recurrence for $T$ corresponds to the expression $\texttt{rec}(\lambda x.a, \lambda x.m)$. As seen in the typing
rules, \texttt{rec} expressions describe recurrences only at type \texttt{real}.
 While this is a very restrictive subset of recursive functions, it allows us to express the recurrences described by 
Karp, while avoiding the problems of the previous approaches. 

\begin{figure}
\[
\begin{array}{lr}
\dfrac{}{\Gamma \vdash \texttt{0}: \texttt{real}}, \ \ \dfrac{}{\Gamma \vdash \texttt{1}: \texttt{real}}, \ldots \\ \\
\dfrac{}{\Gamma \vdash \texttt{true} : \texttt{bool}}, \ \ \dfrac{}{\Gamma \vdash \texttt{false} : \texttt{bool}} \\  \\
\dfrac{x : \tau \in \Gamma}{\Gamma \vdash x : \tau } \\ \\ 
\dfrac{\Gamma, x : \sigma \vdash e : \tau}{\Gamma \vdash \lambda (x : \sigma).e : \sigma \rightarrow \tau } \\ \\
\dfrac{\Gamma \vdash e_1: \sigma \rightarrow \tau \ \ \ \Gamma \vdash e_2 : \sigma}{\Gamma \vdash e_1 \ e_2 : \tau} \\ \\
\dfrac{\Gamma \vdash e_1 : \texttt{real} \ \ \ \Gamma \vdash e_2 : \texttt{real}}{\Gamma \vdash e_1 \circ e_2 : \texttt{real}}
, \circ \in \{+,-,*,/\} \\ \\ 
\dfrac{\Gamma \vdash e_1 : \texttt{real} \ \ \ \Gamma \vdash e_2 : \texttt{real}}{\Gamma \vdash e_1 \circ e_2 : \texttt{bool}}
, \circ \in \{=, <, >, \geq, \leq\} \\ \\ 
\dfrac{\Gamma \vdash e_1 : \texttt{bool} \ \ \ \Gamma \vdash e_2 : \tau \ \ \ \Gamma \vdash e_3 : \tau}
{\Gamma \vdash \ifelse{e_1}{e_2}{e_3} : \tau} \\ \\ 
\dfrac{\Gamma \vdash e_1 : \tau_1 \ \ \ \Gamma \vdash e_2 : \tau_2}{\Gamma \vdash (e_1, e_2) : \tau_1 \times \tau_2} \\ \\
\dfrac{\Gamma \vdash e : \texttt{real}}{\Gamma \vdash \texttt{floor}(e) : \texttt{real}} \\ \\
\dfrac{\Gamma \vdash \lambda x.a : \texttt{real} \rightarrow \texttt{real} \ \ \ \Gamma \vdash \lambda x.m : 
\texttt{real} \rightarrow \texttt{real}} 
{\Gamma \vdash \texttt{rec}(\lambda x.a, \lambda x.m) : \texttt{real} \rightarrow \texttt{real}} 
\end{array}
\]
\caption{Typing for the language.}
\label{fig:typing}
\end{figure}

\begin{figure}
\[
\begin{array}{lr}
e = e \\ \\
\texttt{0} + \texttt{0} = \texttt{0}, \ \texttt{0} + \texttt{1} = 1, \ldots, \ \texttt{3} + \texttt{5} = \texttt{8}, \ldots  \\
\text{equivalent rules for } -, \ * \text{, and } /\text{ operations.}
\\ \\
(n =n) = \texttt{true} \\ (n=m) = \texttt{false}\text{, provided } n, \ m \text{ distinct numerals.}\\ \\ 
\ifelse{\texttt{ true }}{e_1}{e_2} = e_1 \\
\ifelse{\texttt{ false }}{e_1}{e_2} = e_2 \\ \\ 
\lambda x.e = \lambda y.[x \mapsto y]e, \text{provided } y \text{ not free in } e. \\ \\ 
\lambda x.e_1 \ e_2 = [x \mapsto e_2]e_1 \\
\texttt{rec}(\lambda x.a, \lambda x.m) = 
			\lambda x.(a + \texttt{rec}(\lambda x.a, \lambda x.m)(m)) 
\end{array}
\]
\caption{Equational semantics for the language.}
\label{fig:eqsem}
\end{figure}

The denotational semantics for this language is given in Figures 3 and 4. Note, in these figures, that $\Gamma$ is a partial function mapping variables to types, and a
 $\Gamma$-environment $\eta$ is a partial function that maps a variable $x$ to a value in the
 denotation of $\Gamma(x)$. Note, also, that the denotation of $\texttt{real}$, is $\R \cup \{\infty\}$. This is because
 we may write a recurrence of the form $T(x) = a(x) + T(m(x))$ whose only solution is $\infty$---see that this is true
 for $T(x) = 1 + T(x)$.
 Figure 4 defines $\llbracket \Gamma \vdash e: \tau\rrbracket\eta$ for 
a $\Gamma$-environment $\eta$, but we elide mentions of $\Gamma$ and $\tau$ for convenience and just write
$\llbracket e\rrbracket\eta$. Type-soundness is straightforward; thus, proof of the following theorem is omitted.

\begin{thm}
If $\Gamma \vdash e:\tau$, then $\llbracket \Gamma \vdash e : \tau \rrbracket\eta \in \llbracket \tau \rrbracket$.
\end{thm}

\begin{figure}
 \begin{align*}
\llbracket \texttt{real} \rrbracket &= \R_{\infty} \\
 \llbracket \texttt{bool} \rrbracket &= {\{true, false\}} \\
 \llbracket \tau \times \sigma \rrbracket &= \llbracket \tau \rrbracket \times \llbracket \sigma \rrbracket  \\
 \llbracket \tau \rightarrow \sigma \rrbracket &= \{f: \llbracket \tau \rrbracket \rightarrow \llbracket \sigma \rrbracket \mid
 \ f \text{ is continuous}\} 
 \end{align*}
 \caption{Denotational semantics for types.}
 \label{fig:densemtypes}
 \end{figure}
 \begin{figure}
\begin{align*}
 \llbracket \texttt{0} \rrbracket\eta &= 0, \  \llbracket \texttt{1} \rrbracket\eta = 1, \ \ldots \\
  \llbracket x : \tau \rrbracket\eta &= \eta(x) \\
  \llbracket \lambda (x : \tau) . (e : \sigma) \rrbracket\eta &= f : \llbracket \tau \rrbracket \rightarrow \llbracket \sigma \rrbracket \\
\text{ s.t. } \forall d \in \llbracket \tau \rrbracket, f(d) &= \llbracket e \rrbracket\eta\{ x \mapsto d \} \\
 \llbracket e_1 \ e_2 \rrbracket \eta &= \llbracket e_1 \rrbracket\eta ( \llbracket e_2 \rrbracket\eta ) \\
 \llbracket e_1 + e_2 \rrbracket\eta &= \llbracket e_1 \rrbracket\eta + \llbracket e_2 \rrbracket\eta \\
 \llbracket e_1 - e_2 \rrbracket\eta &= \llbracket e_1 \rrbracket\eta - \llbracket e_2 \rrbracket\eta \\
 \llbracket e_1 * e_2 \rrbracket\eta &= \llbracket e_1 \rrbracket\eta * \llbracket e_2 \rrbracket\eta \\
  \llbracket e_1 / e_2 \rrbracket\eta &= \llbracket e_1 \rrbracket\eta / \llbracket e_2 \rrbracket\eta \\
  \llbracket \texttt{true} \rrbracket\eta &= true, \ \llbracket \texttt{false} \rrbracket\eta = false \\
 \llbracket e_1 = e_2 \rrbracket\eta &= 
 \begin{cases} 
      true \text{ if } \llbracket e_1 \rrbracket\eta = \llbracket e_2 \rrbracket\eta \\
      false \text{  if } \llbracket e_1 \rrbracket\eta \neq \llbracket e_2\rrbracket\eta \\
   \end{cases}
 \\
\text{Similar rules for $<, \ \leq , >$\, and $\geq$} \\
  \llbracket \ifelse{e_1}{e_2}{e_3} \rrbracket \eta &= 
 \begin{cases} 
      \llbracket e_2 \rrbracket\eta \text{ if } \llbracket e_1 \rrbracket\eta = true \\
      \llbracket e_3 \rrbracket\eta \text{ if } \llbracket e_1 \rrbracket\eta = false \\
   \end{cases}
  \\
    \llbracket (e_1,e_2) \rrbracket\eta &= (\llbracket e_1 \rrbracket\eta,\llbracket e_2 \rrbracket\eta) \\
    \llbracket \texttt{floor}(e) \rrbracket\eta &= \lfloor \llbracket e \rrbracket\eta \rfloor \\
   \llbracket  \texttt{rec} (\lambda x.a, \lambda x.m) \rrbracket\eta &= rec : \R_{\infty} \rightarrow \R_{\infty} \text{ s.t. } \forall d \in \R_{\infty}, \\
   rec(d) &= \sum_{i=0}^{\infty}\llbracket \lambda x.a \rrbracket\eta ((\llbracket \lambda x.m \rrbracket\eta)^i(d))
 \end{align*}
 \caption{Denotational semantics for expressions.}
 \label{fig:densemexps}
 \end{figure}
 
  We will prove equational soundness of our denotational semantics, in order to ensure that
 our interpretation of recurrences reflects their equational meaning.
 \begin{thm}
  If $\Gamma \vdash e_0 : \tau$ and $\Gamma \vdash e_1 : \tau$ and $e_0 = e_1$, then for all $\Gamma$-environments
  $\eta$,   
 \begin{align*}
 \llbracket \Gamma \vdash e_0 \rrbracket \eta 
 = \llbracket \Gamma \vdash e_1 \rrbracket \eta 
 \end{align*} 
 \end{thm}
 
 \begin{proof}
 We will verify only the equation for $\texttt{rec}$ expressions, as all others are trivial.
 Note that for all $d \in \R_{\infty}$,
 \begin{align*}
 \llbracket \lambda x.(a + \texttt{rec}(\lambda x.a, \lambda x.m)(m)) \rrbracket \eta(d)
 &= \\  
  \llbracket a \rrbracket\{x\mapsto d\} &+ \llbracket \texttt{rec}(\lambda x.a, \lambda x.m)(m)\rrbracket\eta
 \{x\mapsto d\} \\
 = \llbracket \lambda x.a\rrbracket(d) &+ \llbracket\texttt{rec}(\lambda x.a, \lambda x.m)\rrbracket\eta
 (\llbracket m \rrbracket\eta\{x \mapsto d\}) \\
 =  \llbracket \lambda x.a\rrbracket(d) &+ \llbracket\texttt{rec}(\lambda x.a, \lambda x.m)\rrbracket\eta
 (\llbracket \lambda x.m \rrbracket(d)) \\
 = \llbracket \lambda x.a\rrbracket(d) &+ \sum_{i=0}^{\infty} \llbracket \lambda x.a\rrbracket\eta
 ((\llbracket \lambda x.m \rrbracket\eta)^i (d)) \\
 \end{align*}
 \begin{align*}
 = \llbracket \lambda x.a\rrbracket(d) &+ \sum_{i=1}^{\infty} \llbracket \lambda x.a\rrbracket\eta
 ((\llbracket \lambda x.m\rrbracket\eta)^i (d)) \\
&= \sum_{i=0}^\infty \llbracket \lambda x.a \rrbracket\eta ((\llbracket \lambda x.m\rrbracket\eta)^i(d)) \\
&=  \llbracket \texttt{rec}(\lambda x.a, \lambda x.m) \rrbracket \eta (d)
\end{align*}
\end{proof}

We want to gain some intuition that the denotation of a $\texttt{rec}(a,m)$ expression is equal to the solution of the 
corresponding recurrence, $T(x) = a(x) + T(m(x))$.
Consider this example Karp offers, wherein $m(x) = px$, with $p$ a
positive constant less than 1, and $a(x) = 0, \ x < 1, \ a(x) = 1, \ x \geq 1$.
Then $T(x) = a(x) + T(px)$, so by a simple inductive argument we can show that 
\begin{align*}
T(x) &= 
 \begin{cases}
 0 \text{ if } x < 1 \\
 k \text{ if }  \dfrac{1}{p^{k-1}} \leq x < \dfrac{1}{p^k} \\
 \end{cases}
 \end{align*}
 We express this function in our language as follows: 
 \begin{align*}
 \texttt{T} = \texttt{rec}(\lambda x.(\ifelse{x<\texttt{1}}{\texttt{0}}{\texttt{1}}), \lambda x. \texttt{p}*x)
 \end{align*}
 We want to show that the interpretation of this expression has the same solution as the recurrence described by Karp.
 Let $\texttt{a} = \lambda x.\ifelse{x<1}{0}{1}, \ \texttt{m} = \lambda x.\texttt{p}*x$, and see that
 \begin{align*}
  \llbracket \texttt{a} \rrbracket &= a : \R \rightarrow \R \text{ s.t. } a(d) = 0, 
  \ d<1, a(d) = 1, \ d \geq 1  \\
 \llbracket \texttt{m} \rrbracket &= m : \R \rightarrow \R \text{ s.t } \forall d \in \R, \
 m(d) = pd \\
 \llbracket \texttt{T} \rrbracket&= \llbracket \texttt{rec}(\texttt{a}, \texttt{m}) \rrbracket \\
 &= rec: \R \rightarrow \R \text{ s.t. } \forall d \in \R, \\
 &rec(d) = \sum_{i=0}^{\infty}\llbracket \texttt{a} \rrbracket (\llbracket \texttt{m} \rrbracket^i(d)) \\
 &= \sum_{i=0}^{\infty}a (m^i(d)) \\
 &= \sum_{i=0}^{\infty}a (p^i(d))
 \end{align*}
Note that, for all $ d<1 \in \R, \ \llbracket \texttt{T} \rrbracket(d) = 0$
and for all $d \geq 1 \in \R$, since $p < 1, \ \exists k \in \N \text{ s.t } \dfrac{1}{p^{k-1}} \leq d < \dfrac{1}{p^k}$. Then
$p^id < 1$ for $i \geq k$, so
\begin{align*}
\llbracket \texttt{T} \rrbracket(d)&= \sum_{i=0}^{\infty}a (p^i(d)) \\
&= \sum_{i=0}^{k-1}a (p^i(d)) + \sum_{i=k}^{\infty}a (p^i(d)) \\
&= k + 0 = k
\end{align*}
Therefore, $\llbracket \texttt{T} \rrbracket = T$.
 

